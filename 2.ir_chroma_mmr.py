import logging
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
logging.getLogger().setLevel(logging.ERROR)

embeddings = HuggingFaceEmbeddings(model_name="bespin-global/klue-sroberta-base-continue-learning-by-mnr")
db = Chroma(persist_directory="./chroma_db_mmr_1000", embedding_function=embeddings)

queries = [    
                "ì•”í‘ ë¬¼ì§ˆê³¼ ì•”í‘ ì—ë„ˆì§€ì˜ ì°¨ì´ì ", 
                "ë²•ì¸ì¹´ë“œëŠ” ëª‡ ë§¤ì”© ë°°ë¶€í•˜ëŠ”ê²Œ ì›ì¹™ì¸ê°€?",
                "ë²•ì¸ì¹´ë“œ ì‚¬ìš© ì œì•½ ì¡°ê±´",
                "íšŒì˜ë¡ ì‘ì„±ì‹œ ì£¼ì˜ì‚¬í•­",
                "êµ­ì™¸ íŒŒê²¬ì§ì›ì˜ ì—¬ë¹„ ê·œì •ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜",
            ]

def format_docs(docs):
    return "\n\n\tğŸ“‹ ".join([d.page_content for d in docs])

for query in queries:
    embedding_vector = embeddings.embed_query(query)
    # docs = db.similarity_search_by_vector_with_relevance_scores(embedding_vector, 3)
    docs = db.max_marginal_relevance_search_by_vector(embedding_vector, k=5, fetch_k=10, lambda_mult=1)
    print(f">>> QUERY: {query} \n>>> RESULT:")
    for d in docs:
        print(f"ğŸ— {d.page_content}\n  â–«ï¸ ì¶œì²˜: {d.metadata['source']}\n")
    print("â”€" * 100)